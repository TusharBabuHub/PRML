{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbfde5c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-24T16:50:29.480810Z",
     "iopub.status.busy": "2022-08-24T16:50:29.480058Z",
     "iopub.status.idle": "2022-08-24T16:50:29.487087Z",
     "shell.execute_reply": "2022-08-24T16:50:29.486215Z",
     "shell.execute_reply.started": "2022-08-24T16:50:29.480768Z"
    },
    "papermill": {
     "duration": 0.006163,
     "end_time": "2022-08-25T03:05:19.647086",
     "exception": false,
     "start_time": "2022-08-25T03:05:19.640923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Problem Statement\n",
    "We have been hearing about the issue of different types of Full-Self Driving(FSD) technology in mobility domain and the one which has been in news has been predominantly Tesla. The primary objective for a vehicle while driving is to detect varied obstacles and efficiently cross them while following the rules of the road. The signals on the road helps in commuting from one place to another. The dataset we have here are a collation these signals on the road in images. We would use these images to identify the signals.\n",
    "\n",
    "### Data\n",
    "Data has been segregated into two separate folders. \"images\" folder has the collection of all these signal images on the road. \"annotations\" folder has an xml file corresponding to each \"image\" file. The xml file gives the details of the signals present on the image. It helps to locate the signals on the images. The signals are identified as one of the following four\n",
    "1. Speed Limit\n",
    "2. Cross Walk\n",
    "3. Traffic Light\n",
    "4. Stop Sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e06a75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:05:19.659321Z",
     "iopub.status.busy": "2022-08-25T03:05:19.658352Z",
     "iopub.status.idle": "2022-08-25T03:05:19.672989Z",
     "shell.execute_reply": "2022-08-25T03:05:19.671816Z"
    },
    "papermill": {
     "duration": 0.023742,
     "end_time": "2022-08-25T03:05:19.675755",
     "exception": false,
     "start_time": "2022-08-25T03:05:19.652013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a2c3d1",
   "metadata": {
    "papermill": {
     "duration": 0.004293,
     "end_time": "2022-08-25T03:05:19.684619",
     "exception": false,
     "start_time": "2022-08-25T03:05:19.680326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To start with initialise the path of Images and Annotations and create a data frame of image data provided in xml kept in Annotations folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6956e3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:05:19.695696Z",
     "iopub.status.busy": "2022-08-25T03:05:19.694979Z",
     "iopub.status.idle": "2022-08-25T03:05:19.710261Z",
     "shell.execute_reply": "2022-08-25T03:05:19.709116Z"
    },
    "papermill": {
     "duration": 0.023807,
     "end_time": "2022-08-25T03:05:19.712846",
     "exception": false,
     "start_time": "2022-08-25T03:05:19.689039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working directory: /kaggle/working\n",
      "Output Cropped Image directory: /kaggle/working/crop/\n",
      "Input base directory: /kaggle/input/road-sign-detection/\n",
      "Input Image directory: /kaggle/input/road-sign-detection/images/\n",
      "Input Annotations directory: /kaggle/input/road-sign-detection/annotations/\n"
     ]
    }
   ],
   "source": [
    "# Image paths\n",
    "img_base_out = os.getcwd()\n",
    "print(\"Current Working directory:\",img_base_out)\n",
    "img_crop_path_out = img_base_out + '/crop/'\n",
    "print(\"Output Cropped Image directory:\",img_crop_path_out)\n",
    "img_base_in = '/kaggle/input/road-sign-detection/'\n",
    "print(\"Input base directory:\",img_base_in)\n",
    "img_path_in = img_base_in + 'images/'\n",
    "print(\"Input Image directory:\",img_path_in)\n",
    "img_ann_path_in = img_base_in + 'annotations/'\n",
    "print(\"Input Annotations directory:\",img_ann_path_in)\n",
    "\n",
    "# Data Frame column header\n",
    "df_cols = ['ImgID', 'Width', 'Height', 'Type', 'xMin', 'yMin', 'xMax', 'yMax']\n",
    "\n",
    "# Initialise data frame for all files\n",
    "df_files = pd.DataFrame(columns=df_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c48d9dc",
   "metadata": {
    "papermill": {
     "duration": 0.005104,
     "end_time": "2022-08-25T03:05:19.725783",
     "exception": false,
     "start_time": "2022-08-25T03:05:19.720679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Get all the images and annotations in the directory\n",
    "Images are all in png format while annotations are xml format. xml files contain required metadata to read through the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c356db6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:05:19.737551Z",
     "iopub.status.busy": "2022-08-25T03:05:19.736832Z",
     "iopub.status.idle": "2022-08-25T03:05:19.858279Z",
     "shell.execute_reply": "2022-08-25T03:05:19.857074Z"
    },
    "papermill": {
     "duration": 0.130089,
     "end_time": "2022-08-25T03:05:19.860580",
     "exception": false,
     "start_time": "2022-08-25T03:05:19.730491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['road732.xml', 'road518.xml', 'road717.xml', 'road362.xml', 'road492.xml']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise list of files\n",
    "list_of_files = []\n",
    "\n",
    "# Loop each xml file from annotation\n",
    "for dirname, _, filenames in os.walk(img_ann_path_in):\n",
    "    for file in filenames:\n",
    "        if (file.endswith(\".xml\")):\n",
    "            list_of_files.append(file)\n",
    "            \n",
    "list_of_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5606aa",
   "metadata": {
    "papermill": {
     "duration": 0.004577,
     "end_time": "2022-08-25T03:05:19.870694",
     "exception": false,
     "start_time": "2022-08-25T03:05:19.866117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The annotation files give details of different signals available in the images. It also provides us with the boundary of these signals. \n",
    "With this, we can extract multiple images of different signals from the data of boundary provided in the annotation file for each image. To create a predictive model, we would need to convert images into tabular data to assess and predict upon. Further sections of code would talk about analysis of data and the actions being taken via the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9846668",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:05:19.882138Z",
     "iopub.status.busy": "2022-08-25T03:05:19.881370Z",
     "iopub.status.idle": "2022-08-25T03:05:19.887241Z",
     "shell.execute_reply": "2022-08-25T03:05:19.885957Z"
    },
    "papermill": {
     "duration": 0.014383,
     "end_time": "2022-08-25T03:05:19.889683",
     "exception": false,
     "start_time": "2022-08-25T03:05:19.875300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialise the main image data array\n",
    "# Create 785 rows which will be used for row # 0\n",
    "img_data = [(0) for _ in range(785)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fd44f5",
   "metadata": {
    "papermill": {
     "duration": 0.004449,
     "end_time": "2022-08-25T03:05:19.898897",
     "exception": false,
     "start_time": "2022-08-25T03:05:19.894448",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Analysis\n",
    "* Images are all in png format\n",
    "* Each image is of different size\n",
    "* They may contain multiple signals of different sizes\n",
    "* Each image has a corressponding xml file which describes the different types of signal and their position in the image\n",
    "\n",
    "#### Further Actions\n",
    "* Extract the required data from xml file available for each image\n",
    "* Loop through each xml file and use the boundaries provided to crop the image and get just the signal image\n",
    "* Convert the image to a black and white image\n",
    "* Resize the images processed to 28 by 28 pixel dimension. This would create uniformity in the images and will help us in further conversion to an array\n",
    "* Save the processed images and segregate them based on signal type into different folders\n",
    "* Flatten the image data into array data so that we can use it for further prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a9f7b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:05:19.910372Z",
     "iopub.status.busy": "2022-08-25T03:05:19.909675Z",
     "iopub.status.idle": "2022-08-25T03:06:31.870142Z",
     "shell.execute_reply": "2022-08-25T03:06:31.868860Z"
    },
    "papermill": {
     "duration": 71.96939,
     "end_time": "2022-08-25T03:06:31.872997",
     "exception": false,
     "start_time": "2022-08-25T03:05:19.903607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as et\n",
    "from PIL import Image\n",
    "\n",
    "# Create directory for saving cropped images\n",
    "if not os.path.exists(img_crop_path_out):\n",
    "    os.mkdir(img_crop_path_out, mode=0o777)\n",
    "\n",
    "# Loop through each image to get all signals present in it\n",
    "for file in list_of_files:\n",
    "    img_ann_file = img_ann_path_in + file\n",
    "    # Read xml file\n",
    "    img_root = et.parse(img_ann_file)\n",
    "    filename = img_root.find('./filename').text\n",
    "    objects = img_root.findall('./object')\n",
    "    img_width = img_root.find('./size/width').text\n",
    "    img_height = img_root.find('./size/height').text\n",
    "\n",
    "    # Create xml nested table\n",
    "    img_xml_data = [[filename, img_width, img_height, obj.find('./name').text, obj.find('bndbox/xmin').text, obj.find(\n",
    "        'bndbox/ymin').text, obj.find('bndbox/xmax').text, obj.find('bndbox/ymax').text] for obj in objects]\n",
    "\n",
    "    # Create data frame out of the xml extracted data\n",
    "    df_xml = pd.DataFrame(img_xml_data, columns=df_cols)\n",
    "\n",
    "    # Append the new file into the main data frame\n",
    "    df_files = pd.concat([df_files,df_xml], axis=0)\n",
    "\n",
    "    # Open each image and read as balck and white\n",
    "    img = Image.open(img_path_in + filename).convert('L')\n",
    "\n",
    "    # Set image count incase each image has multiple signals\n",
    "    img_count = 0\n",
    "\n",
    "    # Loop through objects to get the boundary of signals in the image\n",
    "    for obj in objects:\n",
    "        xmin = int(obj.find('bndbox/xmin').text)\n",
    "        ymin = int(obj.find('bndbox/ymin').text)\n",
    "        xmax = int(obj.find('bndbox/xmax').text)\n",
    "        ymax = int(obj.find('bndbox/ymax').text)\n",
    "        img_type = obj.find('./name').text\n",
    "        img_count += 1\n",
    "\n",
    "        # Crop image and resize them to dimesions of 28 by 28 pixels\n",
    "        img_crop = img.crop((xmin, ymin, xmax, ymax)).resize((28,28))\n",
    "\n",
    "        # Make sub-directory for each signal type\n",
    "        if not os.path.exists(img_crop_path_out + img_type):\n",
    "            os.mkdir(img_crop_path_out + img_type, mode=0o777)\n",
    "\n",
    "        # Save the cropped image in the specified signal type folder\n",
    "        crop_filepath = img_crop_path_out + img_type + '/' + str(img_count) + \"_\" + filename\n",
    "        img_crop.save(crop_filepath)\n",
    "        \n",
    "        # Convert images into data\n",
    "        # a 28 by 28 array would be created\n",
    "        data = np.array(img_crop)\n",
    "        img_cnv = Image.fromarray(data.astype('uint8'))\n",
    "        img_cnv.save(crop_filepath)\n",
    "        \n",
    "        # Move the 28 rows into single row, which would create 784 columns\n",
    "        data_flatten = data.reshape((1,784))\n",
    "        \n",
    "        # Each row would signify an image which was cropped and converted\n",
    "        # Including a new column which indicates image file name\n",
    "        flnm_array = np.array([str(img_count) + \"_\" + filename.rstrip('.png')])\n",
    "        \n",
    "        # Add image name column to the array\n",
    "        data_flt = np.concatenate((flnm_array,data_flatten), axis = None)\n",
    "        \n",
    "        # Include the new image data into array of previously saved images\n",
    "        img_data = np.vstack((img_data,data_flt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e75249",
   "metadata": {
    "papermill": {
     "duration": 0.004814,
     "end_time": "2022-08-25T03:06:31.882800",
     "exception": false,
     "start_time": "2022-08-25T03:06:31.877986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Check\n",
    "View one of the cropped, resized and, discoloured images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ebed6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:06:31.894510Z",
     "iopub.status.busy": "2022-08-25T03:06:31.893982Z",
     "iopub.status.idle": "2022-08-25T03:06:32.084009Z",
     "shell.execute_reply": "2022-08-25T03:06:32.082837Z"
    },
    "papermill": {
     "duration": 0.198702,
     "end_time": "2022-08-25T03:06:32.086467",
     "exception": false,
     "start_time": "2022-08-25T03:06:31.887765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f448b45a3d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,2))\n",
    "image = img_cnv\n",
    "plt.imshow(np.array(image).reshape(28,28), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29719c9",
   "metadata": {
    "papermill": {
     "duration": 0.004993,
     "end_time": "2022-08-25T03:06:32.097004",
     "exception": false,
     "start_time": "2022-08-25T03:06:32.092011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Check\n",
    "View the image array data created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29db6a09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:06:32.110299Z",
     "iopub.status.busy": "2022-08-25T03:06:32.109585Z",
     "iopub.status.idle": "2022-08-25T03:06:32.117680Z",
     "shell.execute_reply": "2022-08-25T03:06:32.116598Z"
    },
    "papermill": {
     "duration": 0.017481,
     "end_time": "2022-08-25T03:06:32.119915",
     "exception": false,
     "start_time": "2022-08-25T03:06:32.102434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', '0', '0', ..., '0', '0', '0'],\n",
       "       ['1_road732', '181', '185', ..., '107', '119', '110'],\n",
       "       ['2_road732', '100', '115', ..., '84', '103', '93'],\n",
       "       ...,\n",
       "       ['1_road620', '105', '98', ..., '90', '88', '86'],\n",
       "       ['1_road701', '68', '67', ..., '63', '63', '63'],\n",
       "       ['2_road701', '68', '68', ..., '72', '72', '74']], dtype='<U21')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16b15cb",
   "metadata": {
    "papermill": {
     "duration": 0.005032,
     "end_time": "2022-08-25T03:06:32.130594",
     "exception": false,
     "start_time": "2022-08-25T03:06:32.125562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Analysis\n",
    "* Initially, we are trying to identify the speed limits provided on the images. \n",
    "* This would mean, no action being taken on images associated to types CrossWalk, Traffic Light and, Stop Signals.\n",
    "* It would be easy for us to segregate the image type as the earlier cropped, resized and discoloured images which were stored in separate folders.\n",
    "\n",
    "#### Further Action\n",
    "* Get list of images which are classified as speed limit images.\n",
    "* Move images array data into a data frame.\n",
    "* Filter image data frame to extract just the speed limit signal data\n",
    "* Impute a new column with the speed limit numbers found on the image. This column would be used as the Response Variable for our prediction.\n",
    "* Determine why Logistic regression model is suitable for the data.\n",
    "* We will predict the characters of the images by defining the speed limit numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f05e1ccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:06:32.142785Z",
     "iopub.status.busy": "2022-08-25T03:06:32.142338Z",
     "iopub.status.idle": "2022-08-25T03:06:32.298490Z",
     "shell.execute_reply": "2022-08-25T03:06:32.296927Z"
    },
    "papermill": {
     "duration": 0.165829,
     "end_time": "2022-08-25T03:06:32.301700",
     "exception": false,
     "start_time": "2022-08-25T03:06:32.135871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 files which have speed limit are \n",
      " ['1_road519', '1_road344', '1_road215', '1_road466', '1_road308']\n",
      "5 rows from the Dataframe \n",
      "     filename pixel0 pixel1 pixel2 pixel3 pixel4 pixel5 pixel6 pixel7 pixel8  \\\n",
      "1  1_road732    181    185    182    184    185    183    182    192    169   \n",
      "2  2_road732    100    115    123     94    108    105     80     73    102   \n",
      "3  1_road518    164    161    157    158    159    172    117     53     67   \n",
      "4  1_road717     81     80     77     71     68     67     68     71     83   \n",
      "5  2_road717     71     73     75     75     72     71     72     72     65   \n",
      "\n",
      "   ... pixel774 pixel775 pixel776 pixel777 pixel778 pixel779 pixel780  \\\n",
      "1  ...      193      181      133       86      114      138      108   \n",
      "2  ...      215      122       87       84       89      100       89   \n",
      "3  ...      127      148      173      181      158      146      150   \n",
      "4  ...       89       82       78       78       83       84       83   \n",
      "5  ...       92       90       95      107      105       93       78   \n",
      "\n",
      "  pixel781 pixel782 pixel783  \n",
      "1      107      119      110  \n",
      "2       84      103       93  \n",
      "3      152      153      153  \n",
      "4       81       82       83  \n",
      "5       72       73       77  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialise list of files\n",
    "list_of_files = []\n",
    "\n",
    "# SpeedLimit files are stored in folder by name of same signal type\n",
    "# We know the output directory\n",
    "# Loop each directory to find the speed limit files and log the filenames into a list\n",
    "for _, subdirs, _ in os.walk(img_crop_path_out):\n",
    "    for subdir in subdirs:\n",
    "        if (subdir.upper().startswith(\"SPEED\")):\n",
    "            for _,_,filenames in os.walk(img_crop_path_out + subdir):\n",
    "                for file in filenames:\n",
    "                    if (file.endswith(\".png\")):\n",
    "                        list_of_files.append(file.rstrip('.png'))\n",
    "            \n",
    "print('5 files which have speed limit are \\n', list_of_files[:5])\n",
    "\n",
    "# Create column header\n",
    "pixel_columns = [('pixel' + str(count)) for count in range(784)]\n",
    "pixel_columns.insert(0, 'filename')\n",
    "\n",
    "# Create Dataframe out of image data\n",
    "df_img = pd.DataFrame(img_data, columns = pixel_columns)\n",
    "\n",
    "# Filter Dataframe such that it only has images for speed limit\n",
    "df_img_speed = df_img[df_img['filename'].map(lambda x: x).isin(list_of_files)]\n",
    "\n",
    "print('5 rows from the Dataframe \\n',df_img_speed[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14102ea3",
   "metadata": {
    "papermill": {
     "duration": 0.005982,
     "end_time": "2022-08-25T03:06:32.313616",
     "exception": false,
     "start_time": "2022-08-25T03:06:32.307634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Analysis\n",
    "* Now that we have data frame with just the speed limits, we find ourselves with data with numbers in the images\n",
    "* Our plan is to predict the number on the images \n",
    "* This would mean our dataframe should have a column indicating the limit number\n",
    "\n",
    "#### Further Action\n",
    "* Impute a new column with the speed limit numbers found on the image. This column would be used as the Response Variable for our prediction.\n",
    "* We will predict the characters of the images by defining the speed limit numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d27d3e8",
   "metadata": {
    "papermill": {
     "duration": 0.004929,
     "end_time": "2022-08-25T03:06:32.323797",
     "exception": false,
     "start_time": "2022-08-25T03:06:32.318868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a11b3ec",
   "metadata": {
    "papermill": {
     "duration": 0.004866,
     "end_time": "2022-08-25T03:06:32.333824",
     "exception": false,
     "start_time": "2022-08-25T03:06:32.328958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prediction Model\n",
    "Our data is basically a set of images with varying types of signals which are found on the roadways. The objective is to identify/classify these signals into different types. One such type is the speed limit. This type has sub-classification of speed limits on the image. The speed limit values are not continuous and can be considered as a classification For Example, 20, 40, 80 or 100. \n",
    "Logistic regression is a model for classification and the dataframe for speed limit fits the profile for the classification of speeds depicted on these images.\n",
    "\n",
    "#### Further Action\n",
    "* Split the images into Test and Train data at a 40 to 60 split respectively.\n",
    "* Predict the characters of the images by defining the speed limit numbers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 82.371442,
   "end_time": "2022-08-25T03:06:33.060115",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-25T03:05:10.688673",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
