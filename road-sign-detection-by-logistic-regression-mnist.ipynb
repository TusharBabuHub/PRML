{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95106eec",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-24T16:50:29.480810Z",
     "iopub.status.busy": "2022-08-24T16:50:29.480058Z",
     "iopub.status.idle": "2022-08-24T16:50:29.487087Z",
     "shell.execute_reply": "2022-08-24T16:50:29.486215Z",
     "shell.execute_reply.started": "2022-08-24T16:50:29.480768Z"
    },
    "papermill": {
     "duration": 0.00667,
     "end_time": "2022-08-25T02:35:03.149699",
     "exception": false,
     "start_time": "2022-08-25T02:35:03.143029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Problem Statement\n",
    "We have been hearing about the issue of different types of Full-Self Driving(FSD) technology in mobility domain and the one which has been in news has been predominantly Tesla. The primary objective for a vehicle while driving is to detect varied obstacles and efficiently cross them while following the rules of the road. The signals on the road helps in commuting from one place to another. The dataset we have here are a collation these signals on the road in images. We would use these images to identify the signals.\n",
    "\n",
    "### Data\n",
    "Data has been segregated into two separate folders. \"images\" folder has the collection of all these signal images on the road. \"annotations\" folder has an xml file corresponding to each \"image\" file. The xml file gives the details of the signals present on the image. It helps to locate the signals on the images. The signals are identified as one of the following four\n",
    "1. Speed Limit\n",
    "2. Cross Walk\n",
    "3. Traffic Light\n",
    "4. Stop Sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef1de2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T02:35:03.161383Z",
     "iopub.status.busy": "2022-08-25T02:35:03.160877Z",
     "iopub.status.idle": "2022-08-25T02:35:03.172487Z",
     "shell.execute_reply": "2022-08-25T02:35:03.171649Z"
    },
    "papermill": {
     "duration": 0.020235,
     "end_time": "2022-08-25T02:35:03.174898",
     "exception": false,
     "start_time": "2022-08-25T02:35:03.154663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6245736",
   "metadata": {
    "papermill": {
     "duration": 0.003992,
     "end_time": "2022-08-25T02:35:03.183264",
     "exception": false,
     "start_time": "2022-08-25T02:35:03.179272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To start with initialise the path of Images and Annotations and create a data frame of image data provided in xml kept in Annotations folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb88c5d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T02:35:03.194211Z",
     "iopub.status.busy": "2022-08-25T02:35:03.193077Z",
     "iopub.status.idle": "2022-08-25T02:35:03.208869Z",
     "shell.execute_reply": "2022-08-25T02:35:03.208025Z"
    },
    "papermill": {
     "duration": 0.023773,
     "end_time": "2022-08-25T02:35:03.211197",
     "exception": false,
     "start_time": "2022-08-25T02:35:03.187424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working directory /kaggle/working\n",
      "Output Cropped Image directory /kaggle/working/crop/\n",
      "Input base directory /kaggle/input/road-sign-detection/\n",
      "Input Image directory /kaggle/input/road-sign-detection/images/\n",
      "Input Annotations directory /kaggle/input/road-sign-detection/annotations/\n"
     ]
    }
   ],
   "source": [
    "# Image paths\n",
    "img_base_out = os.getcwd()\n",
    "print(\"Current Working directory\",img_base_out)\n",
    "img_crop_path_out = img_base_out + '/crop/'\n",
    "print(\"Output Cropped Image directory\",img_crop_path_out)\n",
    "img_base_in = '/kaggle/input/road-sign-detection/'\n",
    "print(\"Input base directory\",img_base_in)\n",
    "img_path_in = img_base_in + 'images/'\n",
    "print(\"Input Image directory\",img_path_in)\n",
    "img_ann_path_in = img_base_in + 'annotations/'\n",
    "print(\"Input Annotations directory\",img_ann_path_in)\n",
    "\n",
    "# Data Frame column header\n",
    "df_cols = ['ImgID', 'Width', 'Height', 'Type', 'xMin', 'yMin', 'xMax', 'yMax']\n",
    "\n",
    "# Initialise data frame for all files\n",
    "df_files = pd.DataFrame(columns=df_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a6678a",
   "metadata": {
    "papermill": {
     "duration": 0.004016,
     "end_time": "2022-08-25T02:35:03.219584",
     "exception": false,
     "start_time": "2022-08-25T02:35:03.215568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Get all the images and annotations in the directory\n",
    "Images are all in png format while annotations are xml format. xml files contain required metadata to read through the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "823a296b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T02:35:03.230350Z",
     "iopub.status.busy": "2022-08-25T02:35:03.229406Z",
     "iopub.status.idle": "2022-08-25T02:35:03.518367Z",
     "shell.execute_reply": "2022-08-25T02:35:03.517362Z"
    },
    "papermill": {
     "duration": 0.296908,
     "end_time": "2022-08-25T02:35:03.520759",
     "exception": false,
     "start_time": "2022-08-25T02:35:03.223851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['road732.xml', 'road518.xml', 'road717.xml', 'road362.xml', 'road492.xml']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise list of files\n",
    "list_of_files = []\n",
    "\n",
    "# Loop each xml file from annotation\n",
    "for dirname, _, filenames in os.walk(img_ann_path_in):\n",
    "    for file in filenames:\n",
    "        if (file.endswith(\".xml\")):\n",
    "            list_of_files.append(file)\n",
    "            \n",
    "list_of_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1107c49a",
   "metadata": {
    "papermill": {
     "duration": 0.004293,
     "end_time": "2022-08-25T02:35:03.529761",
     "exception": false,
     "start_time": "2022-08-25T02:35:03.525468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The annotation files give details of different signals available in the images. It also provides us with the boundary of these signals. \n",
    "With this, we can extract multiple images of different signals from the data of boundary provided in the annotation file for each image. To create a predictive model, we would need to convert images into tabular data to assess and predict upon. Further sections of code would talk about analysis of data and the actions being taken via the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abe6b70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T02:35:03.541289Z",
     "iopub.status.busy": "2022-08-25T02:35:03.540475Z",
     "iopub.status.idle": "2022-08-25T02:35:03.545838Z",
     "shell.execute_reply": "2022-08-25T02:35:03.545050Z"
    },
    "papermill": {
     "duration": 0.013854,
     "end_time": "2022-08-25T02:35:03.548206",
     "exception": false,
     "start_time": "2022-08-25T02:35:03.534352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialise the main image data array\n",
    "# Create 785 rows which will be used for row # 0\n",
    "img_data = [(0) for _ in range(785)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03acf5c3",
   "metadata": {
    "papermill": {
     "duration": 0.00421,
     "end_time": "2022-08-25T02:35:03.556946",
     "exception": false,
     "start_time": "2022-08-25T02:35:03.552736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Analysis\n",
    "* Images are all in png format\n",
    "* Each image is of different size\n",
    "* They may contain multiple signals of different sizes\n",
    "* Each image has a corressponding xml file which describes the different types of signal and their position in the image\n",
    "\n",
    "#### Further Actions\n",
    "* Extract the required data from xml file available for each image\n",
    "* Loop through each xml file and use the boundaries provided to crop the image and get just the signal image\n",
    "* Convert the image to a black and white image\n",
    "* Resize the images processed to 28 by 28 pixel dimension. This would create uniformity in the images and will help us in further conversion to an array\n",
    "* Save the processed images and segregate them based on signal type into different folders\n",
    "* Flatten the image data into array data so that we can use it for further prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eacfa26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T02:35:03.568349Z",
     "iopub.status.busy": "2022-08-25T02:35:03.567787Z",
     "iopub.status.idle": "2022-08-25T02:36:16.718249Z",
     "shell.execute_reply": "2022-08-25T02:36:16.716957Z"
    },
    "papermill": {
     "duration": 73.159872,
     "end_time": "2022-08-25T02:36:16.721368",
     "exception": false,
     "start_time": "2022-08-25T02:35:03.561496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as et\n",
    "from PIL import Image\n",
    "\n",
    "# Create directory for saving cropped images\n",
    "if not os.path.exists(img_crop_path_out):\n",
    "    os.mkdir(img_crop_path_out, mode=0o777)\n",
    "\n",
    "# Loop through each image to get all signals present in it\n",
    "for file in list_of_files:\n",
    "    img_ann_file = img_ann_path_in + file\n",
    "    # Read xml file\n",
    "    img_root = et.parse(img_ann_file)\n",
    "    filename = img_root.find('./filename').text\n",
    "    objects = img_root.findall('./object')\n",
    "    img_width = img_root.find('./size/width').text\n",
    "    img_height = img_root.find('./size/height').text\n",
    "\n",
    "    # Create xml nested table\n",
    "    img_xml_data = [[filename, img_width, img_height, obj.find('./name').text, obj.find('bndbox/xmin').text, obj.find(\n",
    "        'bndbox/ymin').text, obj.find('bndbox/xmax').text, obj.find('bndbox/ymax').text] for obj in objects]\n",
    "\n",
    "    # Create data frame out of the xml extracted data\n",
    "    df_xml = pd.DataFrame(img_xml_data, columns=df_cols)\n",
    "\n",
    "    # Append the new file into the main data frame\n",
    "    df_files = pd.concat([df_files,df_xml], axis=0)\n",
    "\n",
    "    # Open each image and read as balck and white\n",
    "    img = Image.open(img_path_in + filename).convert('L')\n",
    "\n",
    "    # Set image count incase each image has multiple signals\n",
    "    img_count = 0\n",
    "\n",
    "    # Loop through objects to get the boundary of signals in the image\n",
    "    for obj in objects:\n",
    "        xmin = int(obj.find('bndbox/xmin').text)\n",
    "        ymin = int(obj.find('bndbox/ymin').text)\n",
    "        xmax = int(obj.find('bndbox/xmax').text)\n",
    "        ymax = int(obj.find('bndbox/ymax').text)\n",
    "        img_type = obj.find('./name').text\n",
    "        img_count += 1\n",
    "\n",
    "        # Crop image and resize them to dimesions of 28 by 28 pixels\n",
    "        img_crop = img.crop((xmin, ymin, xmax, ymax)).resize((28,28))\n",
    "\n",
    "        # Make sub-directory for each signal type\n",
    "        if not os.path.exists(img_crop_path_out + img_type):\n",
    "            os.mkdir(img_crop_path_out + img_type, mode=0o777)\n",
    "\n",
    "        # Save the cropped image in the specified signal type folder\n",
    "        crop_filepath = img_crop_path_out + img_type + '/' + str(img_count) + \"_\" + filename\n",
    "        img_crop.save(crop_filepath)\n",
    "        \n",
    "        # Convert images into data\n",
    "        # a 28 by 28 array would be created\n",
    "        data = np.array(img_crop)\n",
    "        img_cnv = Image.fromarray(data.astype('uint8'))\n",
    "        img_cnv.save(crop_filepath)\n",
    "        \n",
    "        # Move the 28 rows into single row, which would create 784 columns\n",
    "        data_flatten = data.reshape((1,784))\n",
    "        \n",
    "        # Each row would signify an image which was cropped and converted\n",
    "        # Including a new column which indicates image file name\n",
    "        flnm_array = np.array([str(img_count) + \"_\" + filename.rstrip('.png')])\n",
    "        \n",
    "        # Add image name column to the array\n",
    "        data_flt = np.concatenate((flnm_array,data_flatten), axis = None)\n",
    "        \n",
    "        # Include the new image data into array of previously saved images\n",
    "        img_data = np.vstack((img_data,data_flt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6892f5b7",
   "metadata": {
    "papermill": {
     "duration": 0.004219,
     "end_time": "2022-08-25T02:36:16.730301",
     "exception": false,
     "start_time": "2022-08-25T02:36:16.726082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Check\n",
    "View one of the cropped, resized and, discoloured images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b2da0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T02:36:16.741222Z",
     "iopub.status.busy": "2022-08-25T02:36:16.740551Z",
     "iopub.status.idle": "2022-08-25T02:36:16.924801Z",
     "shell.execute_reply": "2022-08-25T02:36:16.923560Z"
    },
    "papermill": {
     "duration": 0.192949,
     "end_time": "2022-08-25T02:36:16.927620",
     "exception": false,
     "start_time": "2022-08-25T02:36:16.734671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faaca2d3110>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,2))\n",
    "image = img_cnv\n",
    "plt.imshow(np.array(image).reshape(28,28), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663048b0",
   "metadata": {
    "papermill": {
     "duration": 0.004717,
     "end_time": "2022-08-25T02:36:16.937511",
     "exception": false,
     "start_time": "2022-08-25T02:36:16.932794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Check\n",
    "View the image array data created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2792a76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T02:36:16.948688Z",
     "iopub.status.busy": "2022-08-25T02:36:16.948276Z",
     "iopub.status.idle": "2022-08-25T02:36:16.956069Z",
     "shell.execute_reply": "2022-08-25T02:36:16.954833Z"
    },
    "papermill": {
     "duration": 0.016195,
     "end_time": "2022-08-25T02:36:16.958483",
     "exception": false,
     "start_time": "2022-08-25T02:36:16.942288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', '0', '0', ..., '0', '0', '0'],\n",
       "       ['1_road732', '181', '185', ..., '107', '119', '110'],\n",
       "       ['2_road732', '100', '115', ..., '84', '103', '93'],\n",
       "       ...,\n",
       "       ['1_road620', '105', '98', ..., '90', '88', '86'],\n",
       "       ['1_road701', '68', '67', ..., '63', '63', '63'],\n",
       "       ['2_road701', '68', '68', ..., '72', '72', '74']], dtype='<U21')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da34e41",
   "metadata": {
    "papermill": {
     "duration": 0.004723,
     "end_time": "2022-08-25T02:36:16.968167",
     "exception": false,
     "start_time": "2022-08-25T02:36:16.963444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Analysis\n",
    "* Initially, we are trying to identify the speed limits provided on the images. \n",
    "* This would mean, no action being taken on images associated to types CrossWalk, Traffic Light and, Stop Signals.\n",
    "* It would be easy for us to segregate the image type as the earlier cropped, resized and discoloured images which were stored in separate folders.\n",
    "\n",
    "#### Further Action\n",
    "* Get list of images which are classified as speed limit images.\n",
    "* Move those images array data into a data frame.\n",
    "* Impute a new column with the speed limit numbers found on the image. This column would be used as the Response Variable for our prediction.\n",
    "* Determine why Logistic regression model is suitable for the data.\n",
    "* We will predict the characters of the images by defining the speed limit numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "851d7810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T02:36:16.979934Z",
     "iopub.status.busy": "2022-08-25T02:36:16.979171Z",
     "iopub.status.idle": "2022-08-25T02:36:17.139862Z",
     "shell.execute_reply": "2022-08-25T02:36:17.137809Z"
    },
    "papermill": {
     "duration": 0.16963,
     "end_time": "2022-08-25T02:36:17.142707",
     "exception": false,
     "start_time": "2022-08-25T02:36:16.973077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 files which have speed limit are ['1_road395', '1_road753', '1_road224', '2_road302', '2_road711']\n",
      "       filename pixel0 pixel1 pixel2 pixel3 pixel4 pixel5 pixel6 pixel7  \\\n",
      "1     1_road732    181    185    182    184    185    183    182    192   \n",
      "2     2_road732    100    115    123     94    108    105     80     73   \n",
      "3     1_road518    164    161    157    158    159    172    117     53   \n",
      "4     1_road717     81     80     77     71     68     67     68     71   \n",
      "5     2_road717     71     73     75     75     72     71     72     72   \n",
      "...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "1240  2_road227     92     88     80     71     68     69     77     96   \n",
      "1241  1_road660     80     85     86     88     85     89     87     88   \n",
      "1242  1_road620    105     98     98     99     94     95     93     88   \n",
      "1243  1_road701     68     67     63     65     68     67     66     59   \n",
      "1244  2_road701     68     68     68     67     67     59    119    216   \n",
      "\n",
      "     pixel8  ... pixel774 pixel775 pixel776 pixel777 pixel778 pixel779  \\\n",
      "1       169  ...      193      181      133       86      114      138   \n",
      "2       102  ...      215      122       87       84       89      100   \n",
      "3        67  ...      127      148      173      181      158      146   \n",
      "4        83  ...       89       82       78       78       83       84   \n",
      "5        65  ...       92       90       95      107      105       93   \n",
      "...     ...  ...      ...      ...      ...      ...      ...      ...   \n",
      "1240    118  ...       73       77       81       82       78       72   \n",
      "1241    124  ...      210      215      167      101       72       80   \n",
      "1242     86  ...       88       97      102       99       95       88   \n",
      "1243    141  ...       97       94       88       72       62       63   \n",
      "1244    116  ...       87       88       83       76       69       70   \n",
      "\n",
      "     pixel780 pixel781 pixel782 pixel783  \n",
      "1         108      107      119      110  \n",
      "2          89       84      103       93  \n",
      "3         150      152      153      153  \n",
      "4          83       81       82       83  \n",
      "5          78       72       73       77  \n",
      "...       ...      ...      ...      ...  \n",
      "1240       70       69       70       70  \n",
      "1241       87       87       67       74  \n",
      "1242       89       90       88       86  \n",
      "1243       63       63       63       63  \n",
      "1244       72       72       72       74  \n",
      "\n",
      "[783 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialise list of files\n",
    "list_of_files = []\n",
    "\n",
    "# SpeedLimit files are stored in folder by name of same signal type\n",
    "# We know the output directory\n",
    "# Loop each directory to find the speed limit files and log the filenames into a list\n",
    "for _, subdirs, _ in os.walk(img_crop_path_out):\n",
    "    for subdir in subdirs:\n",
    "        if (subdir.upper().startswith(\"SPEED\")):\n",
    "            for _,_,filenames in os.walk(img_crop_path_out + subdir):\n",
    "                for file in filenames:\n",
    "                    if (file.endswith(\".png\")):\n",
    "                        list_of_files.append(file.rstrip('.png'))\n",
    "            \n",
    "print('5 files which have speed limit are', list_of_files[:5])\n",
    "\n",
    "# Create column header\n",
    "pixel_columns = [('pixel' + str(count)) for count in range(784)]\n",
    "pixel_columns.insert(0, 'filename')\n",
    "\n",
    "# Create Dataframe out of image data\n",
    "df_img = pd.DataFrame(img_data, columns = pixel_columns)\n",
    "\n",
    "# Filter Dataframe such that it only has images for speed limit\n",
    "df_img_speed = df_img[df_img['filename'].map(lambda x: x).isin(list_of_files)]\n",
    "\n",
    "print(df_img_speed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 83.96323,
   "end_time": "2022-08-25T02:36:17.869495",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-25T02:34:53.906265",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
