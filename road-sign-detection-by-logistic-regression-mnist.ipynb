{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df9c92f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-24T16:50:29.480810Z",
     "iopub.status.busy": "2022-08-24T16:50:29.480058Z",
     "iopub.status.idle": "2022-08-24T16:50:29.487087Z",
     "shell.execute_reply": "2022-08-24T16:50:29.486215Z",
     "shell.execute_reply.started": "2022-08-24T16:50:29.480768Z"
    },
    "papermill": {
     "duration": 0.009418,
     "end_time": "2022-08-25T11:26:50.630902",
     "exception": false,
     "start_time": "2022-08-25T11:26:50.621484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Problem Statement\n",
    "We have been hearing about the issue of different types of Full-Self Driving(FSD) technology in mobility domain and the one which has been in news has been predominantly Tesla. The primary objective for a vehicle while driving is to detect varied obstacles and efficiently cross them while following the rules of the road. The signals on the road helps in commuting from one place to another. The dataset we have here are a collation these signals on the road in images. We would use these images to identify the signals.\n",
    "\n",
    "### Data\n",
    "Data has been segregated into two separate folders. \"images\" folder has the collection of all these signal images on the road. \"annotations\" folder has an xml file corresponding to each \"image\" file. The xml file gives the details of the signals present on the image. It helps to locate the signals on the images. The signals are identified as one of the following four\n",
    "1. Speed Limit\n",
    "2. Cross Walk\n",
    "3. Traffic Light\n",
    "4. Stop Sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee1308b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T11:26:50.647133Z",
     "iopub.status.busy": "2022-08-25T11:26:50.646583Z",
     "iopub.status.idle": "2022-08-25T11:26:50.660720Z",
     "shell.execute_reply": "2022-08-25T11:26:50.659734Z"
    },
    "papermill": {
     "duration": 0.025289,
     "end_time": "2022-08-25T11:26:50.663037",
     "exception": false,
     "start_time": "2022-08-25T11:26:50.637748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ecde4",
   "metadata": {
    "papermill": {
     "duration": 0.006532,
     "end_time": "2022-08-25T11:26:50.676420",
     "exception": false,
     "start_time": "2022-08-25T11:26:50.669888",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To start with initialise the path of Images and Annotations and create a data frame of image data provided in xml kept in Annotations folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37bff094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T11:26:50.692882Z",
     "iopub.status.busy": "2022-08-25T11:26:50.691926Z",
     "iopub.status.idle": "2022-08-25T11:26:50.709256Z",
     "shell.execute_reply": "2022-08-25T11:26:50.708180Z"
    },
    "papermill": {
     "duration": 0.029559,
     "end_time": "2022-08-25T11:26:50.712721",
     "exception": false,
     "start_time": "2022-08-25T11:26:50.683162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working directory: /kaggle/working\n",
      "Output Cropped Image directory: /kaggle/working/crop/\n",
      "Input base directory: /kaggle/input/road-sign-detection/\n",
      "Input Image directory: /kaggle/input/road-sign-detection/images/\n",
      "Input Annotations directory: /kaggle/input/road-sign-detection/annotations/\n"
     ]
    }
   ],
   "source": [
    "# Image paths\n",
    "img_base_out = os.getcwd()\n",
    "print(\"Current Working directory:\",img_base_out)\n",
    "img_crop_path_out = img_base_out + '/crop/'\n",
    "print(\"Output Cropped Image directory:\",img_crop_path_out)\n",
    "img_base_in = '/kaggle/input/road-sign-detection/'\n",
    "print(\"Input base directory:\",img_base_in)\n",
    "img_path_in = img_base_in + 'images/'\n",
    "print(\"Input Image directory:\",img_path_in)\n",
    "img_ann_path_in = img_base_in + 'annotations/'\n",
    "print(\"Input Annotations directory:\",img_ann_path_in)\n",
    "\n",
    "# Data Frame column header\n",
    "df_cols = ['ImgID', 'Width', 'Height', 'Type', 'xMin', 'yMin', 'xMax', 'yMax']\n",
    "\n",
    "# Initialise data frame for all files\n",
    "df_files = pd.DataFrame(columns=df_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3c04a5",
   "metadata": {
    "papermill": {
     "duration": 0.00659,
     "end_time": "2022-08-25T11:26:50.727278",
     "exception": false,
     "start_time": "2022-08-25T11:26:50.720688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Get all the images and annotations in the directory\n",
    "Images are all in png format while annotations are xml format. xml files contain required metadata to read through the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e9e7e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T11:26:50.743551Z",
     "iopub.status.busy": "2022-08-25T11:26:50.742705Z",
     "iopub.status.idle": "2022-08-25T11:26:51.005226Z",
     "shell.execute_reply": "2022-08-25T11:26:51.003557Z"
    },
    "papermill": {
     "duration": 0.275014,
     "end_time": "2022-08-25T11:26:51.009060",
     "exception": false,
     "start_time": "2022-08-25T11:26:50.734046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['road732.xml', 'road518.xml', 'road717.xml', 'road362.xml', 'road492.xml']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise list of files\n",
    "list_of_files = []\n",
    "\n",
    "# Loop each xml file from annotation\n",
    "for dirname, _, filenames in os.walk(img_ann_path_in):\n",
    "    for file in filenames:\n",
    "        if (file.endswith(\".xml\")):\n",
    "            list_of_files.append(file)\n",
    "            \n",
    "list_of_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd706ff",
   "metadata": {
    "papermill": {
     "duration": 0.006767,
     "end_time": "2022-08-25T11:26:51.023366",
     "exception": false,
     "start_time": "2022-08-25T11:26:51.016599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The annotation files give details of different signals available in the images. It also provides us with the boundary of these signals. \n",
    "With this, we can extract multiple images of different signals from the data of boundary provided in the annotation file for each image. To create a predictive model, we would need to convert images into tabular data to assess and predict upon. Further sections of code would talk about analysis of data and the actions being taken via the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ef3753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T11:26:51.039874Z",
     "iopub.status.busy": "2022-08-25T11:26:51.039015Z",
     "iopub.status.idle": "2022-08-25T11:26:51.044107Z",
     "shell.execute_reply": "2022-08-25T11:26:51.043134Z"
    },
    "papermill": {
     "duration": 0.016193,
     "end_time": "2022-08-25T11:26:51.046503",
     "exception": false,
     "start_time": "2022-08-25T11:26:51.030310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialise the main image data array\n",
    "# Create 785 rows which will be used for row # 0\n",
    "img_data = [(0) for _ in range(785)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc8dd4",
   "metadata": {
    "papermill": {
     "duration": 0.006625,
     "end_time": "2022-08-25T11:26:51.060163",
     "exception": false,
     "start_time": "2022-08-25T11:26:51.053538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Analysis\n",
    "* Images are all in png format\n",
    "* Each image is of different size\n",
    "* They may contain multiple signals of different sizes\n",
    "* Each image has a corressponding xml file which describes the different types of signal and their position in the image\n",
    "\n",
    "#### Further Actions\n",
    "* Extract the required data from xml file available for each image\n",
    "* Loop through each xml file and use the boundaries provided to crop the image and get just the signal image\n",
    "* Convert the image to a black and white image\n",
    "* Resize the images processed to 28 by 28 pixel dimension. This would create uniformity in the images and will help us in further conversion to an array\n",
    "* Save the processed images and segregate them based on signal type into different folders\n",
    "* Flatten the image data into array data so that we can use it for further prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75a67c31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T11:26:51.076762Z",
     "iopub.status.busy": "2022-08-25T11:26:51.075920Z",
     "iopub.status.idle": "2022-08-25T11:28:15.138276Z",
     "shell.execute_reply": "2022-08-25T11:28:15.136610Z"
    },
    "papermill": {
     "duration": 84.074908,
     "end_time": "2022-08-25T11:28:15.141993",
     "exception": false,
     "start_time": "2022-08-25T11:26:51.067085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as et\n",
    "from PIL import Image\n",
    "\n",
    "# Create directory for saving cropped images\n",
    "if not os.path.exists(img_crop_path_out):\n",
    "    os.mkdir(img_crop_path_out, mode=0o777)\n",
    "\n",
    "# Loop through each image to get all signals present in it\n",
    "for file in list_of_files:\n",
    "    img_ann_file = img_ann_path_in + file\n",
    "    # Read xml file\n",
    "    img_root = et.parse(img_ann_file)\n",
    "    filename = img_root.find('./filename').text\n",
    "    objects = img_root.findall('./object')\n",
    "    img_width = img_root.find('./size/width').text\n",
    "    img_height = img_root.find('./size/height').text\n",
    "\n",
    "    # Create xml nested table\n",
    "    img_xml_data = [[filename, img_width, img_height, obj.find('./name').text, obj.find('bndbox/xmin').text, obj.find(\n",
    "        'bndbox/ymin').text, obj.find('bndbox/xmax').text, obj.find('bndbox/ymax').text] for obj in objects]\n",
    "\n",
    "    # Create data frame out of the xml extracted data\n",
    "    df_xml = pd.DataFrame(img_xml_data, columns=df_cols)\n",
    "\n",
    "    # Append the new file into the main data frame\n",
    "    df_files = pd.concat([df_files,df_xml], axis=0)\n",
    "\n",
    "    # Open each image and read as balck and white\n",
    "    img = Image.open(img_path_in + filename).convert('L')\n",
    "\n",
    "    # Set image count incase each image has multiple signals\n",
    "    img_count = 0\n",
    "\n",
    "    # Loop through objects to get the boundary of signals in the image\n",
    "    for obj in objects:\n",
    "        xmin = int(obj.find('bndbox/xmin').text)\n",
    "        ymin = int(obj.find('bndbox/ymin').text)\n",
    "        xmax = int(obj.find('bndbox/xmax').text)\n",
    "        ymax = int(obj.find('bndbox/ymax').text)\n",
    "        img_type = obj.find('./name').text\n",
    "        img_count += 1\n",
    "\n",
    "        # Crop image and resize them to dimesions of 28 by 28 pixels\n",
    "        img_crop = img.crop((xmin, ymin, xmax, ymax)).resize((28,28))\n",
    "\n",
    "        # Make sub-directory for each signal type\n",
    "        if not os.path.exists(img_crop_path_out + img_type):\n",
    "            os.mkdir(img_crop_path_out + img_type, mode=0o777)\n",
    "\n",
    "        # Save the cropped image in the specified signal type folder\n",
    "        crop_filepath = img_crop_path_out + img_type + '/' + str(img_count) + \"_\" + filename\n",
    "        img_crop.save(crop_filepath)\n",
    "        \n",
    "        # Convert images into data\n",
    "        # a 28 by 28 array would be created\n",
    "        data = np.array(img_crop)\n",
    "        img_cnv = Image.fromarray(data.astype('uint8'))\n",
    "        img_cnv.save(crop_filepath)\n",
    "        \n",
    "        # Move the 28 rows into single row, which would create 784 columns\n",
    "        data_flatten = data.reshape((1,784))\n",
    "        \n",
    "        # Each row would signify an image which was cropped and converted\n",
    "        # Including a new column which indicates image file name\n",
    "        flnm_array = np.array([str(img_count) + \"_\" + filename.rstrip('.png')])\n",
    "        \n",
    "        # Add image name column to the array\n",
    "        data_flt = np.concatenate((flnm_array,data_flatten), axis = None)\n",
    "        \n",
    "        # Include the new image data into array of previously saved images\n",
    "        img_data = np.vstack((img_data,data_flt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc8834f",
   "metadata": {
    "papermill": {
     "duration": 0.007229,
     "end_time": "2022-08-25T11:28:15.158790",
     "exception": false,
     "start_time": "2022-08-25T11:28:15.151561",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Check\n",
    "View one of the cropped, resized and, discoloured images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5d52f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T11:28:15.175754Z",
     "iopub.status.busy": "2022-08-25T11:28:15.175285Z",
     "iopub.status.idle": "2022-08-25T11:28:15.375865Z",
     "shell.execute_reply": "2022-08-25T11:28:15.374339Z"
    },
    "papermill": {
     "duration": 0.212533,
     "end_time": "2022-08-25T11:28:15.378840",
     "exception": false,
     "start_time": "2022-08-25T11:28:15.166307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdc6a518a10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,2))\n",
    "image = img_cnv\n",
    "plt.imshow(np.array(image).reshape(28,28), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5eecc0",
   "metadata": {
    "papermill": {
     "duration": 0.007099,
     "end_time": "2022-08-25T11:28:15.393703",
     "exception": false,
     "start_time": "2022-08-25T11:28:15.386604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Check\n",
    "View the image array data created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59e68df1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T11:28:15.411592Z",
     "iopub.status.busy": "2022-08-25T11:28:15.410687Z",
     "iopub.status.idle": "2022-08-25T11:28:15.419083Z",
     "shell.execute_reply": "2022-08-25T11:28:15.417874Z"
    },
    "papermill": {
     "duration": 0.020249,
     "end_time": "2022-08-25T11:28:15.421568",
     "exception": false,
     "start_time": "2022-08-25T11:28:15.401319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', '0', '0', ..., '0', '0', '0'],\n",
       "       ['1_road732', '181', '185', ..., '107', '119', '110'],\n",
       "       ['2_road732', '100', '115', ..., '84', '103', '93'],\n",
       "       ...,\n",
       "       ['1_road620', '105', '98', ..., '90', '88', '86'],\n",
       "       ['1_road701', '68', '67', ..., '63', '63', '63'],\n",
       "       ['2_road701', '68', '68', ..., '72', '72', '74']], dtype='<U21')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9131d2ff",
   "metadata": {
    "papermill": {
     "duration": 0.007354,
     "end_time": "2022-08-25T11:28:15.436555",
     "exception": false,
     "start_time": "2022-08-25T11:28:15.429201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Analysis\n",
    "* Initially, we are trying to identify the speed limits provided on the images. \n",
    "* This would mean, no action being taken on images associated to types CrossWalk, Traffic Light and, Stop Signals.\n",
    "* It would be easy for us to segregate the image type as the earlier cropped, resized and discoloured images which were stored in separate folders.\n",
    "\n",
    "#### Further Action\n",
    "* Get list of images which are classified as speed limit images.\n",
    "* Move images array data into a data frame.\n",
    "* Filter image data frame to extract just the speed limit signal data\n",
    "* Impute a new column with the speed limit numbers found on the image. This column would be used as the Response Variable for our prediction.\n",
    "* Determine why Logistic regression model is suitable for the data.\n",
    "* We will predict the characters of the images by defining the speed limit numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a601a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T11:28:15.454900Z",
     "iopub.status.busy": "2022-08-25T11:28:15.453946Z",
     "iopub.status.idle": "2022-08-25T11:28:24.803275Z",
     "shell.execute_reply": "2022-08-25T11:28:24.802333Z"
    },
    "papermill": {
     "duration": 9.361345,
     "end_time": "2022-08-25T11:28:24.805627",
     "exception": false,
     "start_time": "2022-08-25T11:28:15.444282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_road732</td>\n",
       "      <td>181</td>\n",
       "      <td>185</td>\n",
       "      <td>182</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>183</td>\n",
       "      <td>182</td>\n",
       "      <td>192</td>\n",
       "      <td>169</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>181</td>\n",
       "      <td>133</td>\n",
       "      <td>86</td>\n",
       "      <td>114</td>\n",
       "      <td>138</td>\n",
       "      <td>108</td>\n",
       "      <td>107</td>\n",
       "      <td>119</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_road732</td>\n",
       "      <td>100</td>\n",
       "      <td>115</td>\n",
       "      <td>123</td>\n",
       "      <td>94</td>\n",
       "      <td>108</td>\n",
       "      <td>105</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>215</td>\n",
       "      <td>122</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>89</td>\n",
       "      <td>100</td>\n",
       "      <td>89</td>\n",
       "      <td>84</td>\n",
       "      <td>103</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_road518</td>\n",
       "      <td>164</td>\n",
       "      <td>161</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>53</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>148</td>\n",
       "      <td>173</td>\n",
       "      <td>181</td>\n",
       "      <td>158</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>152</td>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_road717</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>71</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>83</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2_road717</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>72</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>107</td>\n",
       "      <td>105</td>\n",
       "      <td>93</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "1  1_road732     181     185     182     184     185     183     182     192   \n",
       "2  2_road732     100     115     123      94     108     105      80      73   \n",
       "3  1_road518     164     161     157     158     159     172     117      53   \n",
       "4  1_road717      81      80      77      71      68      67      68      71   \n",
       "5  2_road717      71      73      75      75      72      71      72      72   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "1     169  ...       193       181       133        86       114       138   \n",
       "2     102  ...       215       122        87        84        89       100   \n",
       "3      67  ...       127       148       173       181       158       146   \n",
       "4      83  ...        89        82        78        78        83        84   \n",
       "5      65  ...        92        90        95       107       105        93   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "1       108       107       119       110  \n",
       "2        89        84       103        93  \n",
       "3       150       152       153       153  \n",
       "4        83        81        82        83  \n",
       "5        78        72        73        77  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise list of files\n",
    "list_of_files = []\n",
    "\n",
    "# SpeedLimit files are stored in folder by name of same signal type\n",
    "# We know the output directory\n",
    "# Loop each directory to find the speed limit files and log the filenames into a list\n",
    "for _, subdirs, _ in os.walk(img_crop_path_out):\n",
    "    for subdir in subdirs:\n",
    "        if (subdir.upper().startswith(\"SPEED\")):\n",
    "            for _,_,filenames in os.walk(img_crop_path_out + subdir):\n",
    "                for file in filenames:\n",
    "                    if (file.endswith(\".png\")):\n",
    "                        list_of_files.append(file.rstrip('.png'))\n",
    "            \n",
    "# Create column headers\n",
    "pixel_columns = [('pixel' + str(count)) for count in range(784)]\n",
    "pixel_columns.insert(0, 'filename')\n",
    "\n",
    "# Create Dataframe out of image data\n",
    "df_img = pd.DataFrame(img_data, columns = pixel_columns)\n",
    "\n",
    "# Filter Dataframe such that it only has images for speed limit\n",
    "df_img_speed = df_img[df_img['filename'].map(lambda x: x).isin(list_of_files)]\n",
    "\n",
    "# Convert the pixel values to int\n",
    "df_img_speed[df_img_speed.columns[1:785]] = df_img_speed[df_img_speed.columns[1:785]].astype(int)\n",
    "\n",
    "df_img_speed[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d93e7f",
   "metadata": {
    "papermill": {
     "duration": 0.007742,
     "end_time": "2022-08-25T11:28:24.821528",
     "exception": false,
     "start_time": "2022-08-25T11:28:24.813786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Analysis\n",
    "* Now that we have data frame with just the speed limits, we find ourselves with data with numbers in the images\n",
    "* Our plan is to predict the number on the images \n",
    "* This would mean our dataframe should have a column indicating the limit number\n",
    "\n",
    "#### Further Action\n",
    "* Impute a new column with the speed limit numbers found on the image. This column would be used as the Response Variable for our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f3cd173",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T11:28:24.840623Z",
     "iopub.status.busy": "2022-08-25T11:28:24.839357Z",
     "iopub.status.idle": "2022-08-25T11:28:24.960154Z",
     "shell.execute_reply": "2022-08-25T11:28:24.959321Z"
    },
    "papermill": {
     "duration": 0.133345,
     "end_time": "2022-08-25T11:28:24.963025",
     "exception": false,
     "start_time": "2022-08-25T11:28:24.829680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_road732</td>\n",
       "      <td>181</td>\n",
       "      <td>185</td>\n",
       "      <td>182</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>183</td>\n",
       "      <td>182</td>\n",
       "      <td>192</td>\n",
       "      <td>169</td>\n",
       "      <td>...</td>\n",
       "      <td>181</td>\n",
       "      <td>133</td>\n",
       "      <td>86</td>\n",
       "      <td>114</td>\n",
       "      <td>138</td>\n",
       "      <td>108</td>\n",
       "      <td>107</td>\n",
       "      <td>119</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_road732</td>\n",
       "      <td>100</td>\n",
       "      <td>115</td>\n",
       "      <td>123</td>\n",
       "      <td>94</td>\n",
       "      <td>108</td>\n",
       "      <td>105</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>89</td>\n",
       "      <td>100</td>\n",
       "      <td>89</td>\n",
       "      <td>84</td>\n",
       "      <td>103</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_road518</td>\n",
       "      <td>164</td>\n",
       "      <td>161</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>53</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>173</td>\n",
       "      <td>181</td>\n",
       "      <td>158</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>152</td>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_road717</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>71</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>83</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_road717</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>72</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>107</td>\n",
       "      <td>105</td>\n",
       "      <td>93</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>77</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>2_road227</td>\n",
       "      <td>92</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>71</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>77</td>\n",
       "      <td>96</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>1_road660</td>\n",
       "      <td>80</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>88</td>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>124</td>\n",
       "      <td>...</td>\n",
       "      <td>215</td>\n",
       "      <td>167</td>\n",
       "      <td>101</td>\n",
       "      <td>72</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>67</td>\n",
       "      <td>74</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>1_road620</td>\n",
       "      <td>105</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>102</td>\n",
       "      <td>99</td>\n",
       "      <td>95</td>\n",
       "      <td>88</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>1_road701</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>59</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>88</td>\n",
       "      <td>72</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>2_road701</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>59</td>\n",
       "      <td>119</td>\n",
       "      <td>216</td>\n",
       "      <td>116</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>83</td>\n",
       "      <td>76</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>783 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  \\\n",
       "0    1_road732     181     185     182     184     185     183     182   \n",
       "1    2_road732     100     115     123      94     108     105      80   \n",
       "2    1_road518     164     161     157     158     159     172     117   \n",
       "3    1_road717      81      80      77      71      68      67      68   \n",
       "4    2_road717      71      73      75      75      72      71      72   \n",
       "..         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "778  2_road227      92      88      80      71      68      69      77   \n",
       "779  1_road660      80      85      86      88      85      89      87   \n",
       "780  1_road620     105      98      98      99      94      95      93   \n",
       "781  1_road701      68      67      63      65      68      67      66   \n",
       "782  2_road701      68      68      68      67      67      59     119   \n",
       "\n",
       "     pixel7  pixel8  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       192     169  ...       181       133        86       114       138   \n",
       "1        73     102  ...       122        87        84        89       100   \n",
       "2        53      67  ...       148       173       181       158       146   \n",
       "3        71      83  ...        82        78        78        83        84   \n",
       "4        72      65  ...        90        95       107       105        93   \n",
       "..      ...     ...  ...       ...       ...       ...       ...       ...   \n",
       "778      96     118  ...        77        81        82        78        72   \n",
       "779      88     124  ...       215       167       101        72        80   \n",
       "780      88      86  ...        97       102        99        95        88   \n",
       "781      59     141  ...        94        88        72        62        63   \n",
       "782     216     116  ...        88        83        76        69        70   \n",
       "\n",
       "     pixel780  pixel781  pixel782  pixel783  speed  \n",
       "0         108       107       119       110    120  \n",
       "1          89        84       103        93    100  \n",
       "2         150       152       153       153     80  \n",
       "3          83        81        82        83    100  \n",
       "4          78        72        73        77    120  \n",
       "..        ...       ...       ...       ...    ...  \n",
       "778        70        69        70        70    100  \n",
       "779        87        87        67        74     40  \n",
       "780        89        90        88        86     50  \n",
       "781        63        63        63        63    120  \n",
       "782        72        72        72        74    100  \n",
       "\n",
       "[783 rows x 786 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load csv file which has speed values indicated on the signal\n",
    "data_speed = pd.read_csv('/kaggle/input/road-sign-detection-speed-limit/speedlimit.csv',header = None, names = ['Id','speed'])\n",
    "\n",
    "# Join the dataframes to process further\n",
    "speedlimit_data = pd.merge(df_img_speed, data_speed, left_on='filename', right_on='Id', how='left').drop('Id', axis=1)\n",
    "speedlimit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331d8660",
   "metadata": {
    "papermill": {
     "duration": 0.008786,
     "end_time": "2022-08-25T11:28:24.980841",
     "exception": false,
     "start_time": "2022-08-25T11:28:24.972055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prediction Model\n",
    "Our data is basically a set of images with varying types of signals which are found on the roadways. The objective is to identify/classify these signals into different types. One such type is the speed limit, this can be sub-classified based on speeds indicated on the image. The speed limit values are not continuous and can be considered as a classification For Example, 5, 20, 40, 80 or 100. \n",
    "Logistic regression is a model for classification and the data for speed limit fits the profile for the classification of speeds depicted on these images.\n",
    "\n",
    "#### Further Action\n",
    "* Set target variable\n",
    "* Split the images into Test and Train data at a 40 to 60 split respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95bc94c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T11:28:25.000546Z",
     "iopub.status.busy": "2022-08-25T11:28:24.999654Z",
     "iopub.status.idle": "2022-08-25T11:28:26.385548Z",
     "shell.execute_reply": "2022-08-25T11:28:26.384209Z"
    },
    "papermill": {
     "duration": 1.399057,
     "end_time": "2022-08-25T11:28:26.388700",
     "exception": false,
     "start_time": "2022-08-25T11:28:24.989643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Get Explanatory variables\n",
    "x = speedlimit_data[speedlimit_data.columns[1:785]]\n",
    "\n",
    "# Get the Response variable\n",
    "y = speedlimit_data[['speed']]\n",
    "\n",
    "# Split the data\n",
    "Ex_train,Ex_test,Res_train,Res_test = train_test_split(x,y,train_size=.6,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5fc5b9",
   "metadata": {
    "papermill": {
     "duration": 0.007827,
     "end_time": "2022-08-25T11:28:26.405129",
     "exception": false,
     "start_time": "2022-08-25T11:28:26.397302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Analysis\n",
    "* With 783 images, we are using 60% of data to fit our model\n",
    "\n",
    "#### Further Action\n",
    "* Select the classifier\n",
    "* Fit the data using the classifier model\n",
    "* Predict the characters of the images by defining the speed limit numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cf11066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T11:28:26.423518Z",
     "iopub.status.busy": "2022-08-25T11:28:26.422995Z",
     "iopub.status.idle": "2022-08-25T11:28:27.723138Z",
     "shell.execute_reply": "2022-08-25T11:28:27.721370Z"
    },
    "papermill": {
     "duration": 1.317327,
     "end_time": "2022-08-25T11:28:27.730515",
     "exception": false,
     "start_time": "2022-08-25T11:28:26.413188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 50,  40,  40,  40,  80, 100,  40, 120,  40,  60,  40,  60,  90,\n",
       "        40,  40,  80,  60,  40,  40,  40, 100,  80,  80,  40,  90,  80,\n",
       "        60,  40, 100, 100,  80, 100, 120, 100,  40,  40, 120,  80, 120,\n",
       "        50, 100,  80, 100,  40, 120,  80,  40, 100,  80,  40,  80,  90,\n",
       "        80,  80,  40,  40,  70,  90, 100, 120, 100,  40,  90,  80,  40,\n",
       "        40, 100,  60, 100,  40,   5,  90,  40,  60, 100, 120, 100,  40,\n",
       "        80,  50,  80,  30, 100,  80,  90,  50,  80,   5, 120,  90,  40,\n",
       "        90,   5,  40,  40, 100,  80,  40,  70, 120, 100,  70, 100,  60,\n",
       "        40,  80,  70, 100, 100,  80,  40, 100,  80,  40,  40, 120,  40,\n",
       "        40,  80, 120, 100, 120,  40,  80,  60,  90,  80,  80,  40, 100,\n",
       "        70,  80,  40,  40,  30, 100,  80,  40,  80,  40,  80,  80, 100,\n",
       "       120,  40,  50,  90, 120,  80, 100,  80,  80,  60, 120,  80,  40,\n",
       "        40,  80,  80,  40,  60,  40, 120, 120,  80,  80,  40,  70,  80,\n",
       "       100,  40,  90,  50,  40,  30,  90,  90,  40, 100,  30,  50,  40,\n",
       "        50,  40, 120,  40,  90,   5,  80,  80, 120,  40,  30,  60,  90,\n",
       "        90,   5,  30, 100,  40,  40, 100, 120, 100,  80,  90,  90, 100,\n",
       "        80,  80,  40,  60,  40, 120,  60, 120,  70,  40,  40,  40,  40,\n",
       "        30, 120,  30, 120,  80,  40,  40, 100,  40,  40, 120,  40,   5,\n",
       "        40, 120, 120,  40,  40, 100,  60,  40,   5,  40,  50,  50, 100,\n",
       "       100,  40,  80,  80,  80,  40, 100, 120,  40, 100,  50, 100,   5,\n",
       "        40,  80,  40,  40, 120, 100,  40,  80, 100,  40,  40, 100,  40,\n",
       "        40,   5,  90,  80,  40, 100,  80,  40,  30,  90,  50,  60,  30,\n",
       "       120, 120,  40,  90, 100,  60,   5,  40, 100,  80,   5,  80,  40,\n",
       "       100,  40,  80, 120,  90,  80,  40,  40,  80,  40, 100,  80, 120,\n",
       "       100,  80])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set logistic regression model\n",
    "logR = LogisticRegression(solver = 'lbfgs', max_iter = 100)\n",
    "\n",
    "# Fit data using the model\n",
    "logR.fit(Ex_train,Res_train)\n",
    "\n",
    "# Predict test response based on test explanatory data\n",
    "Res_predict = logR.predict(Ex_test)\n",
    "Res_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449f7478",
   "metadata": {
    "papermill": {
     "duration": 0.021629,
     "end_time": "2022-08-25T11:28:27.795147",
     "exception": false,
     "start_time": "2022-08-25T11:28:27.773518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Once the data has been fitted and predicted, we have to analyse the score of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ad9c98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T11:28:27.834171Z",
     "iopub.status.busy": "2022-08-25T11:28:27.833783Z",
     "iopub.status.idle": "2022-08-25T11:28:27.853451Z",
     "shell.execute_reply": "2022-08-25T11:28:27.852199Z"
    },
    "papermill": {
     "duration": 0.041786,
     "end_time": "2022-08-25T11:28:27.858820",
     "exception": false,
     "start_time": "2022-08-25T11:28:27.817034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8885350318471338\n"
     ]
    }
   ],
   "source": [
    "Test_Score = logR.score(Ex_test,Res_test)\n",
    "print(Test_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e60237c",
   "metadata": {
    "papermill": {
     "duration": 0.020528,
     "end_time": "2022-08-25T11:28:27.901084",
     "exception": false,
     "start_time": "2022-08-25T11:28:27.880556",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Evaluate model using Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c009fb87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T11:28:27.946819Z",
     "iopub.status.busy": "2022-08-25T11:28:27.946125Z",
     "iopub.status.idle": "2022-08-25T11:28:27.968017Z",
     "shell.execute_reply": "2022-08-25T11:28:27.966442Z"
    },
    "papermill": {
     "duration": 0.047947,
     "end_time": "2022-08-25T11:28:27.971169",
     "exception": false,
     "start_time": "2022-08-25T11:28:27.923222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0,  0,  0,  0,  0,  0,  1,  1,  0,  0],\n",
       "       [ 0,  9,  1,  1,  0,  1,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0, 82,  1,  1,  0,  1,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  8,  0,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1,  0, 12,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  1,  2,  0,  0,  5,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  4,  1,  0,  0, 56,  1,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  2,  1,  0, 20,  0,  0,  0],\n",
       "       [ 0,  0,  3,  1,  1,  0,  1,  0, 46,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  1,  0, 30]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Res_test, Res_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8387513b",
   "metadata": {
    "papermill": {
     "duration": 0.008582,
     "end_time": "2022-08-25T11:28:27.989150",
     "exception": false,
     "start_time": "2022-08-25T11:28:27.980568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Display Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5ebe32c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T11:28:28.013090Z",
     "iopub.status.busy": "2022-08-25T11:28:28.012266Z",
     "iopub.status.idle": "2022-08-25T11:28:28.567115Z",
     "shell.execute_reply": "2022-08-25T11:28:28.565698Z"
    },
    "papermill": {
     "duration": 0.571661,
     "end_time": "2022-08-25T11:28:28.570045",
     "exception": false,
     "start_time": "2022-08-25T11:28:27.998384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_predictions = list(zip(speedlimit_data,logR.predict(x)))\n",
    "\n",
    "plt.figure(figsize=(10,2))\n",
    "for idx in range(5):\n",
    "    image = x.iloc[idx,:]\n",
    "    prediction = logR.predict(x)[idx]\n",
    "    plt.subplot(1,5,idx+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.array(image).reshape(28, 28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % int(prediction))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25bc6cd",
   "metadata": {
    "papermill": {
     "duration": 0.009213,
     "end_time": "2022-08-25T11:28:28.588528",
     "exception": false,
     "start_time": "2022-08-25T11:28:28.579315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Display incorrectly predicted speed limit signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "068b6b1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T11:28:28.609367Z",
     "iopub.status.busy": "2022-08-25T11:28:28.608648Z",
     "iopub.status.idle": "2022-08-25T11:28:28.616890Z",
     "shell.execute_reply": "2022-08-25T11:28:28.615569Z"
    },
    "papermill": {
     "duration": 0.021762,
     "end_time": "2022-08-25T11:28:28.619361",
     "exception": false,
     "start_time": "2022-08-25T11:28:28.597599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "misclassifiedIndexes = []\n",
    "for actual, predicted in zip(Res_test, Res_predict):\n",
    "    if actual != predicted: \n",
    "        misclassifiedIndexes.append(idx)\n",
    "    idx +=1\n",
    "\n",
    "misclassifiedIndexes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 109.188317,
   "end_time": "2022-08-25T11:28:29.452158",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-25T11:26:40.263841",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
